{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ccceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468663d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_folder = \"C:/Users/nicho/Desktop/Thesis Work/11-11-25/\"  # repalce with folder path of where data should go\n",
    "sensors_used = [\"A5F2\", \"A19E\"]       # replace with name of raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcbc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to hold sensor name and dataframe associated\n",
    "dfs = {}\n",
    "latest_starting_time = None\n",
    "earliest_ending_time = None\n",
    "\n",
    "for sensor in sensors_used:\n",
    "    df_raw = pd.read_csv(trial_folder + sensor + \".csv\", sep='\\t', skiprows=1)\n",
    "    df_raw = df_raw.drop(columns=[col for col in df_raw.columns if \"Unnamed\" in col], errors='ignore')\n",
    "\n",
    "    # first row contains units — remove it and reset index\n",
    "    df = df_raw.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # convert all columns to numeric\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    dfs[sensor] = df\n",
    "\n",
    "    starting_time = df.iloc[0][f'Shimmer_{sensor}_TimestampSync_Unix_CAL']\n",
    "    ending_time = df.iloc[-1][f'Shimmer_{sensor}_TimestampSync_Unix_CAL']\n",
    "    \n",
    "    if latest_starting_time == None or starting_time > latest_starting_time:\n",
    "        latest_starting_time = starting_time\n",
    "        latest_start_sensor = sensor\n",
    "    \n",
    "    if earliest_ending_time == None or ending_time < earliest_ending_time:\n",
    "        earliest_ending_time = ending_time\n",
    "        earliest_end_sensor = sensor\n",
    "print(latest_start_sensor)\n",
    "print(earliest_end_sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864611e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_sensor = None\n",
    "if earliest_end_sensor == latest_start_sensor:\n",
    "    master_sensor = earliest_end_sensor\n",
    "else:\n",
    "    latest_start_df = dfs[latest_start_sensor]\n",
    "    dfs[latest_start_sensor] = latest_start_df[latest_start_df[f'Shimmer_{latest_start_sensor}_TimestampSync_Unix_CAL'] <= earliest_ending_time]\n",
    "    master_sensor = latest_start_sensor\n",
    "\n",
    "nonmaster_sensor = None\n",
    "for sensor in sensors_used:\n",
    "    if sensor != master_sensor:\n",
    "        nonmaster_sensor = sensor\n",
    "print(master_sensor)\n",
    "print(nonmaster_sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(master_sensor)\n",
    "print(nonmaster_sensor)\n",
    "for sensor in sensors_used:\n",
    "    print(sensor)\n",
    "    print(dfs[sensor].iloc[0][f'Shimmer_{sensor}_TimestampSync_Unix_CAL'])\n",
    "    print(dfs[sensor].iloc[-1][f'Shimmer_{sensor}_TimestampSync_Unix_CAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_shimmers(\n",
    "    df_master: pd.DataFrame,\n",
    "    t_master: str,\n",
    "    master_name: str,\n",
    "    df_other: pd.DataFrame,\n",
    "    t_other: str,\n",
    "    other_name: str,\n",
    "    tolerance: float = 10,   # milliseconds\n",
    "    keep_other_time: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Align (snap) df_other to df_master's timeline using nearest-neighbor on timestamps,\n",
    "    then return a single DataFrame on the master time grid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_master : DataFrame\n",
    "        The 'master' sensor data. Its time column defines the output timeline.\n",
    "    t_master : str\n",
    "        Name of the master time column.\n",
    "    df_other : DataFrame\n",
    "        The other sensor's data to be aligned to the master timeline.\n",
    "    t_other : str\n",
    "        Name of the other sensor's time column\n",
    "    tolerance : float, default 10ms\n",
    "        Max allowed absolute time difference  for a match. Rows without a\n",
    "        nearby sample within this window remain NaN for the other sensor's columns.\n",
    "        For 50 Hz (20 ms period), ±10 ms is a good default.\n",
    "    keep_other_time : bool, default False\n",
    "        If True, keep df_other's time column (it will be renamed with the prefix).\n",
    "        If False, drop it (you'll have a single, master time column).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        df_master columns (unchanged) + df_other columns (prefixed), aligned to the\n",
    "        master timeline, with a single master time column unless keep_other_time=True.\n",
    "    \"\"\"\n",
    "    # Safety: merge_asof requires sorted keys\n",
    "    left = df_master.sort_values(t_master).reset_index(drop=True)\n",
    "    left = left.rename(columns={f'Shimmer_{master_name}_Event_Marker_CAL': 'Event_Marker'})\n",
    "    right = df_other.sort_values(t_other).reset_index(drop=True)\n",
    "    right = right.drop(f'Shimmer_{other_name}_Event_Marker_CAL', axis=1)\n",
    "    \n",
    "    merged = pd.merge_asof(\n",
    "        left,\n",
    "        right,\n",
    "        left_on=t_master,\n",
    "        right_on=t_other,\n",
    "        direction='nearest',\n",
    "        tolerance=tolerance,\n",
    "    )\n",
    "\n",
    "    if not keep_other_time and t_other in merged.columns:\n",
    "        merged = merged.drop(columns=[t_other])\n",
    "\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea976dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_shimmers(df_master=dfs[master_sensor], \n",
    "                        t_master=f'Shimmer_{master_sensor}_TimestampSync_Unix_CAL',\n",
    "                        master_name=master_sensor, \n",
    "                        df_other=dfs[nonmaster_sensor],\n",
    "                        t_other=f'Shimmer_{nonmaster_sensor}_TimestampSync_Unix_CAL',\n",
    "                        other_name=nonmaster_sensor,\n",
    "                        tolerance=10,\n",
    "                        keep_other_time=False\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "# convert timestamp to relative time (seconds)\n",
    "if f'Shimmer_{master_sensor}_TimestampSync_Unix_CAL' in merged.columns:\n",
    "    merged['Time (s)'] = (merged[f'Shimmer_{master_sensor}_TimestampSync_Unix_CAL'] - merged[f'Shimmer_{master_sensor}_TimestampSync_Unix_CAL'].iloc[0]) / 1000\n",
    "\n",
    "# drop unwanted columns\n",
    "drop_cols = []\n",
    "for sensor_id in sensors_used:\n",
    "    drop_cols.append(f\"Shimmer_{sensor_id}_Battery_CAL\")\n",
    "    drop_cols.append(f\"Shimmer_{sensor_id}_ECG_EMG_Status1_CAL\")\n",
    "    drop_cols.append(f'Shimmer_{sensor_id}_TimestampSync_Unix_CAL')\n",
    "merged = merged.drop(columns=[c for c in drop_cols if c in merged.columns], errors='ignore')\n",
    "\n",
    "rename_map = {}\n",
    "for sensor_id in sensors_used:\n",
    "    rename_map.update({\n",
    "        f'Shimmer_{sensor_id}_Accel_LN_X_CAL': f'{sensor_id}_AccelX',\n",
    "        f'Shimmer_{sensor_id}_Accel_LN_Y_CAL': f'{sensor_id}_AccelY',\n",
    "        f'Shimmer_{sensor_id}_Accel_LN_Z_CAL': f'{sensor_id}_AccelZ',\n",
    "        f'Shimmer_{sensor_id}_EMG_CH1_24BIT_CAL': f'{sensor_id}_EMG1',\n",
    "        f'Shimmer_{sensor_id}_EMG_CH2_24BIT_CAL': f'{sensor_id}_EMG2',\n",
    "        f'Shimmer_{sensor_id}_Gyro_X_CAL': f'{sensor_id}_GyroX',\n",
    "        f'Shimmer_{sensor_id}_Gyro_Y_CAL': f'{sensor_id}_GyroY',\n",
    "        f'Shimmer_{sensor_id}_Gyro_Z_CAL': f'{sensor_id}_GyroZ',\n",
    "        f'Shimmer_{sensor_id}_Mag_X_CAL': f'{sensor_id}_MagX',\n",
    "        f'Shimmer_{sensor_id}_Mag_Y_CAL': f'{sensor_id}_MagY',\n",
    "        f'Shimmer_{sensor_id}_Mag_Z_CAL': f'{sensor_id}_MagZ',\n",
    "    })\n",
    "merged = merged.rename(columns=rename_map)\n",
    "\n",
    "merged.to_csv(trial_folder + \"merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# helper function to create interactive line plots\n",
    "def plot_group(df, group_cols, title):\n",
    "    fig = go.Figure()\n",
    "    for col in group_cols:\n",
    "        fig.add_trace(go.Scatter(x=df['Time (s)'], y=df[col], mode='lines', name=col))\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Time (s)\",\n",
    "        yaxis_title=\"Sensor Value\",\n",
    "        hovermode=\"x unified\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# %%\n",
    "# identify column groups\n",
    "emg_cols = [c for c in merged.columns if \"EMG\" in c]\n",
    "accel_cols = [c for c in merged.columns if \"Accel\" in c]\n",
    "gyro_cols = [c for c in merged.columns if \"Gyro\" in c]\n",
    "mag_cols = [c for c in merged.columns if \"Mag\" in c]\n",
    "\n",
    "# %%\n",
    "# --- plot each sensor group ---\n",
    "if emg_cols:\n",
    "    plot_group(merged, emg_cols, \"EMG Channels\")\n",
    "\n",
    "if accel_cols:\n",
    "    plot_group(merged, accel_cols, \"Accelerometer (X, Y, Z)\")\n",
    "\n",
    "if gyro_cols:\n",
    "    plot_group(merged, gyro_cols, \"Gyroscope (X, Y, Z)\")\n",
    "\n",
    "if mag_cols:\n",
    "    plot_group(merged, mag_cols, \"Magnetometer (X, Y, Z)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb809719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(trial_folder + \"merged.csv\")\n",
    "print(df.columns)\n",
    "print(df.iloc[-1]['Time (s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b459f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = df.loc[df['Event_Marker'] > 0, 'Time (s)'].iloc[0]\n",
    "end_time = df.loc[df['Event_Marker'] > 0, 'Time (s)'].iloc[-1]\n",
    "print(start_time)\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = 35.7979\n",
    "trimmed_video_len = 492.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8508a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_df(df, start_time, total_time):\n",
    "    \"\"\"\n",
    "    Trim the dataframe to only include rows where 'Time (s)' \n",
    "    is between start_time and total_time + start_time.\n",
    "    Then reset time so it starts at 0.\n",
    "    \"\"\"\n",
    "    trimmed_df = df[(df[\"Time (s)\"] >= start_time) & (df[\"Time (s)\"] <= total_time + start_time)].copy()\n",
    "    trimmed_df[\"Time (s)\"] = trimmed_df[\"Time (s)\"] - start_time\n",
    "    trimmed_df.reset_index(drop=True, inplace=True)\n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim dataframe to sync with video\n",
    "df = trim_df(df, start_time, trimmed_video_len) \n",
    "print(df['Time (s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video_path = trial_folder + \"trimmed_finalized.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n",
    "\n",
    "print(f\"FPS: {fps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0127fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames = 54149\n",
    "json_path = trial_folder + \"labels\" + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(trial_folder + \"merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fps(df, frames):\n",
    "    start = df.iloc[0]['Time (s)']\n",
    "    end = df.iloc[-1]['Time (s)']\n",
    "    dt = end - start\n",
    "    return frames / dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f894cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load JSON labels\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# collect start/end frames per annotation\n",
    "annotations_list = []\n",
    "for task in data:\n",
    "    for annotation in task.get(\"annotations\", []):\n",
    "        for result in annotation.get(\"result\", []):\n",
    "            label = result[\"value\"][\"timelinelabels\"][0]\n",
    "            start = result[\"value\"][\"ranges\"][0][\"start\"]\n",
    "            end = result[\"value\"][\"ranges\"][0][\"end\"]\n",
    "\n",
    "            annotations_list.append({\n",
    "                \"label\": label,\n",
    "                \"start_frame\": start,\n",
    "                \"end_frame\": end\n",
    "            })\n",
    "\n",
    "# get fps of video\n",
    "fps = get_fps(df, total_frames)\n",
    "\n",
    "for item in annotations_list:\n",
    "    label = item['label']\n",
    "    start_time = (item['start_frame'] - 1) / fps\n",
    "    end_time = (item['end_frame'] - 1) / fps\n",
    "    df.loc[(df[\"Time (s)\"] >= start_time) & (df[\"Time (s)\"] <= end_time), \"Primitive\"] = label\n",
    "\n",
    "    mask = (df[\"Time (s)\"] >= start_time) & (df[\"Time (s)\"] <= end_time)\n",
    "    indices = df.index[mask]\n",
    "\n",
    "    if not indices.empty:\n",
    "        df.loc[indices[0], \"Primitive\"] = \"Start\"\n",
    "        df.loc[indices[-1], \"Primitive\"] = \"End\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd90c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, sosfiltfilt, iirnotch, filtfilt\n",
    "\n",
    "\n",
    "# gather list of emg columns\n",
    "emg_columns = []\n",
    "for sensor_id in sensors_used:\n",
    "    emg_columns.append(f'{sensor_id}_EMG1')\n",
    "    emg_columns.append(f'{sensor_id}_EMG2')\n",
    "\n",
    "\n",
    "# get sampling rate from time differences\n",
    "dt = np.diff(df[\"Time (s)\"].to_numpy())\n",
    "fs = float(np.round(1.0/np.median(dt[dt>0])))\n",
    "nyq = 0.5*fs\n",
    "\n",
    "# bandpass filter: keeps the core EMG frequency band where motor-unit signals live and rejects everything else\n",
    "def bp_sos(low, high, order=4):\n",
    "    return butter(order, [low/nyq, high/nyq], btype='bandpass', output='sos')\n",
    "\n",
    "# high pass filter: removes slow drift and movement artifacts so only muscle activity remains\n",
    "def hp_sos(cut, order=2):\n",
    "    return butter(order, cut/nyq, btype='highpass', output='sos')\n",
    "\n",
    "# narrow notch filter to remove power line interference\n",
    "def notch_once(x, f0, Q=35):\n",
    "    if f0 >= nyq: return x\n",
    "    w0 = f0/(fs/2); b, a = iirnotch(w0, Q)\n",
    "    return filtfilt(b, a, x)\n",
    "\n",
    "# linear envelope: full-wave rectification followed by low-pass filter to smooth\n",
    "def linear_envelope(x, lp=5.0):\n",
    "    rect = np.abs(x)\n",
    "    sos_lp = butter(4, lp/nyq, btype='lowpass', output='sos')\n",
    "    return sosfiltfilt(sos_lp, rect)\n",
    "\n",
    "# filters\n",
    "sos_hp = hp_sos(20.0, order=2)\n",
    "sos_bp = bp_sos(20.0, min(240.0, 0.45*fs), order=4)\n",
    "\n",
    "for col in emg_columns:\n",
    "    x = df[col].astype(float).interpolate('linear').to_numpy()\n",
    "\n",
    "    # high pass\n",
    "    x = sosfiltfilt(sos_hp, x)\n",
    "\n",
    "    # notch 60 & 120\n",
    "    x = notch_once(x, 60); x = notch_once(x, 120)\n",
    "\n",
    "    # bandpass\n",
    "    x_bp = sosfiltfilt(sos_bp, x)\n",
    "\n",
    "    # envelope\n",
    "    env = linear_envelope(x_bp, lp=5.0)\n",
    "\n",
    "    # save both normally filtered and enveloped signal\n",
    "    df[col] = x_bp\n",
    "    df[col + \"_ENV\"] = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_fs_modality(df, axes, time_col=\"Time (s)\", eps=1e-6):\n",
    "    \"\"\"\n",
    "    Estimate IMU sampling rate for a modality (e.g., ['AccelX','AccelY','AccelZ'])\n",
    "    by detecting rows where ANY axis changes value. Returns a float fs_est (Hz).\n",
    "    \"\"\"\n",
    "    t = df[time_col].to_numpy()\n",
    "    X = df[axes].to_numpy(dtype=float)\n",
    "    # mark where any axis changes between rows\n",
    "    change = (np.abs(np.diff(X, axis=0)) > eps).any(axis=1)\n",
    "    change_times = t[1:][change]\n",
    "    if change_times.size < 2:\n",
    "        return None\n",
    "    dt = np.diff(change_times)\n",
    "    dt = dt[dt > 0]\n",
    "    if dt.size == 0:\n",
    "        return None\n",
    "    fs_est = 1.0 / np.median(dt)  # robust estimate\n",
    "    return float(fs_est)\n",
    "\n",
    "fs_accel = estimate_fs_modality(df, [f'{sensor_id}_AccelX',f'{sensor_id}_AccelX',f'{sensor_id}_AccelZ'])\n",
    "fs_gyro  = estimate_fs_modality(df, [f'{sensor_id}_GyroX',f'{sensor_id}_GyroY',f'{sensor_id}_GyroZ'])\n",
    "fs_mag   = estimate_fs_modality(df, [f'{sensor_id}_MagX',f'{sensor_id}_MagY',f'{sensor_id}_MagZ'])\n",
    "print(fs_accel)\n",
    "print(fs_gyro)\n",
    "print(fs_mag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfiltfilt\n",
    "\n",
    "# -- IMU FILTER HELPERS --\n",
    "\n",
    "# lowpass filter\n",
    "def lowpass_sos(data, cutoff, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    sos = butter(order, cutoff/nyq, btype=\"low\", output=\"sos\")\n",
    "    return sosfiltfilt(sos, data)\n",
    "\n",
    "def highpass_sos(data, cutoff, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    sos = butter(order, cutoff/nyq, btype=\"highpass\", output=\"sos\")\n",
    "    return sosfiltfilt(sos, data)\n",
    "\n",
    "for col in accel_cols:\n",
    "    df[col + \"_DYN\"] = highpass_sos(df[col], cutoff=0.3, fs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather list of accelerometer columns\n",
    "accel_cols = []\n",
    "for sensor_id in sensors_used:\n",
    "    accel_cols.append(f'{sensor_id}_AccelX')\n",
    "    accel_cols.append(f'{sensor_id}_AccelY')\n",
    "    accel_cols.append(f'{sensor_id}_AccelZ')\n",
    "\n",
    "for col in accel_cols:\n",
    "    df[col] = lowpass_sos(df[col], cutoff=20, fs=fs_accel)\n",
    "    df[col + \"_DYN\"] = highpass_sos(df[col], cutoff=0.3, fs=50) # cut out gravity with high pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d70dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather list of accelerometer columns\n",
    "gyro_cols = []\n",
    "for sensor_id in sensors_used:\n",
    "    gyro_cols.append(f'{sensor_id}_GyroX')\n",
    "    gyro_cols.append(f'{sensor_id}_GyroY')\n",
    "    gyro_cols.append(f'{sensor_id}_GyroZ')\n",
    "\n",
    "for col in gyro_cols:\n",
    "    df[col] = lowpass_sos(df[col], cutoff=20, fs=fs_gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather list of accelerometer columns\n",
    "mag_cols = []\n",
    "for sensor_id in sensors_used:\n",
    "    mag_cols.append(f'{sensor_id}_MagX')\n",
    "    mag_cols.append(f'{sensor_id}_MagY')\n",
    "    mag_cols.append(f'{sensor_id}_MagZ')\n",
    "\n",
    "for col in mag_cols:\n",
    "    df[col] = lowpass_sos(df[col], cutoff=10, fs=fs_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d72bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for sensor_id in sensors_used:\n",
    "    df[f\"{sensor_id}_AccelMag\"] = np.sqrt(df[f'{sensor_id}_AccelX']**2 + df[f'{sensor_id}_AccelY']**2 + df[f'{sensor_id}_AccelZ']**2)\n",
    "    df[f\"{sensor_id}_GyroMag\"]  = np.sqrt(df[f'{sensor_id}_GyroX']**2  + df[f'{sensor_id}_GyroY']**2  + df[f'{sensor_id}_GyroZ']**2)\n",
    "    df[f\"{sensor_id}_MagnetMag\"]   = np.sqrt(df[f'{sensor_id}_MagX']**2   + df[f'{sensor_id}_MagY']**2   + df[f'{sensor_id}_MagZ']**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in accel_cols + gyro_cols + mag_cols:\n",
    "    mu, sigma = df[col].mean(), df[col].std()\n",
    "    df[col + \"_Z\"] = (df[col] - mu) / (sigma + 1e-8)\n",
    "\n",
    "for sensor_id in sensors_used:\n",
    "    for col in [f\"{sensor_id}_AccelMag\"] + [f\"{sensor_id}_GyroMag\"] + [f\"{sensor_id}_MagnetMag\"]:\n",
    "        mu, sigma = df[col].mean(), df[col].std()\n",
    "        df[col + \"_Z\"] = (df[col] - mu) / (sigma + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(trial_folder + \"data_labeled\" + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# --- Define channels dynamically based on sensor_ids ---\n",
    "channels = {}\n",
    "for sensor_id in sensors_used:\n",
    "    channels.update({\n",
    "        f\"{sensor_id} EMG1\": f\"{sensor_id}_EMG1_ENV\",\n",
    "        f\"{sensor_id} EMG2\": f\"{sensor_id}_EMG2_ENV\",\n",
    "        f\"{sensor_id} Accel X\": f\"{sensor_id}_AccelX\",\n",
    "        f\"{sensor_id} Accel Y\": f\"{sensor_id}_AccelY\",\n",
    "        f\"{sensor_id} Accel Z\": f\"{sensor_id}_AccelZ\",\n",
    "        f\"{sensor_id} Gyro X\": f\"{sensor_id}_GyroX\",\n",
    "        f\"{sensor_id} Gyro Y\": f\"{sensor_id}_GyroY\",\n",
    "        f\"{sensor_id} Gyro Z\": f\"{sensor_id}_GyroZ\",\n",
    "        f\"{sensor_id} Mag X\": f\"{sensor_id}_MagX\",\n",
    "        f\"{sensor_id} Mag Y\": f\"{sensor_id}_MagY\",\n",
    "        f\"{sensor_id} Mag Z\": f\"{sensor_id}_MagZ\",\n",
    "    })\n",
    "\n",
    "# --- Build contiguous primitive segments ---\n",
    "df[\"Primitive_Change\"] = (df[\"Primitive\"] != df[\"Primitive\"].shift()).cumsum()\n",
    "\n",
    "# --- Create a large distinct color palette ---\n",
    "distinct_colors = (\n",
    "    px.colors.qualitative.Bold +\n",
    "    px.colors.qualitative.Safe +\n",
    "    px.colors.qualitative.Dark24 +\n",
    "    px.colors.qualitative.Light24\n",
    ")\n",
    "\n",
    "# --- Assign colors to primitives ---\n",
    "unique_primitives = df[\"Primitive\"].unique()\n",
    "primitive_color_map = {p: distinct_colors[i % len(distinct_colors)] for i, p in enumerate(unique_primitives)}\n",
    "\n",
    "# --- Create subplots ---\n",
    "fig = make_subplots(\n",
    "    rows=len(channels),\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.02,\n",
    "    subplot_titles=list(channels.keys())\n",
    ")\n",
    "\n",
    "# --- Plot each channel ---\n",
    "for i, (name, col) in enumerate(channels.items(), start=1):\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "\n",
    "    added_labels = set()  # track which primitives have been added to legend\n",
    "\n",
    "    for _, seg in df.groupby(\"Primitive_Change\"):\n",
    "        primitive = seg[\"Primitive\"].iloc[0]\n",
    "        color = primitive_color_map.get(primitive, \"blue\")\n",
    "\n",
    "        # Show legend only for first subplot\n",
    "        show_legend = (i == 1) and (primitive not in added_labels)\n",
    "\n",
    "        # --- Plot main signal segment ---\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=seg[\"Time (s)\"] if \"Time (s)\" in df.columns else seg.index,\n",
    "                y=seg[col],\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=color, width=1.5),\n",
    "                name=primitive,\n",
    "                showlegend=show_legend,\n",
    "                hovertemplate=f\"<b>{name}</b><br>Primitive: {primitive}<br>Time: %{{x}}<br>Value: %{{y}}<extra></extra>\"\n",
    "            ),\n",
    "            row=i,\n",
    "            col=1\n",
    "        )\n",
    "        added_labels.add(primitive)\n",
    "\n",
    "# --- Layout ---\n",
    "fig.update_layout(\n",
    "    height=300*len(channels),  # dynamic height\n",
    "    showlegend=True,\n",
    "    legend_title=\"Primitive / Marker\",\n",
    "    title=\"Shimmer Sensor Channel Dashboard\",\n",
    "    hovermode=\"x unified\",\n",
    "    margin=dict(t=50, b=30, l=30, r=30),\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
