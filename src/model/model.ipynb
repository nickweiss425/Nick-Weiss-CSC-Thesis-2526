{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c529ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import butter, sosfiltfilt, iirnotch, filtfilt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f0cfa7",
   "metadata": {},
   "source": [
    "## **Load Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b61497",
   "metadata": {},
   "source": [
    "**Load Raw Data Files from Each Participant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c11e4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folder that holds participant data\n",
    "data_path = \"C:/Users/nicho/Desktop/Nick-Weiss-CSC-Thesis-2526/data\"\n",
    "\n",
    "# get all the folders inside data directory that hold individual trials\n",
    "participant_folders = [\n",
    "    entry for entry in os.listdir(data_path) \n",
    "    if os.path.isdir(os.path.join(data_path, entry))\n",
    "]\n",
    "\n",
    "# keep list of all dataframes\n",
    "dfs = []\n",
    "\n",
    "# folder name is the participant id\n",
    "# ****MIGHT CHANGE THE FORMAT OF THE FOLDER LATER --> COME BACK TO THIS****\n",
    "for participant_id in participant_folders:\n",
    "    # get the path to the finalized data file\n",
    "    csv_path = os.path.join(\n",
    "        data_path, \n",
    "        participant_id, \n",
    "        \"finalized_data.csv\"\n",
    "    )\n",
    "    \n",
    "    # print error if csv not found\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Skipping Participant {participant_id}: finalized_data.csv not found in {os.path.join(data_path, participant_id)}\" )\n",
    "    else:\n",
    "        # read csv into dataframe\n",
    "        participant_df = pd.read_csv(csv_path)\n",
    "\n",
    "        # add participant id column and append to list\n",
    "        participant_df['participant_id'] = participant_id\n",
    "        dfs.append(participant_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0eaec",
   "metadata": {},
   "source": [
    "**Clean Dataframes to ensure proper labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cced6bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_participant_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # drop rows that are entirely empty\n",
    "    df = df.dropna(how=\"all\").copy()\n",
    "\n",
    "    # check that df includes required columns\n",
    "    time_col = \"Time (s)\"\n",
    "    label_col = \"Primitive\"\n",
    "    required_cols = [time_col, label_col]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"{df['participant_id'].iloc[0]}: missing required column '{col}'\")\n",
    "\n",
    "    # make sure time column is numeric\n",
    "    df[time_col] = pd.to_numeric(df[time_col], errors=\"coerce\")\n",
    "\n",
    "    # remove rows where Time (s) is NaN, orders rows by increasing time, reset df indices\n",
    "    df = df.dropna(subset=[time_col]).sort_values(time_col)\n",
    "\n",
    "    # drop duplicated time rows (keep first occurrance)\n",
    "    df = df.drop_duplicates(subset=[time_col], keep=\"first\")\n",
    "\n",
    "    # force labels to be text and strip whitespace\n",
    "    df[label_col] = df[label_col].astype(\"string\").str.strip()\n",
    "\n",
    "    # only keep rows that have a valid label attached\n",
    "    df = df[df[label_col].notna() & (df[label_col] != \"\")]\n",
    "\n",
    "    return df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf4f80",
   "metadata": {},
   "source": [
    "**Estimating Sampling Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f033d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_fs_from_time(df: pd.DataFrame) -> float:\n",
    "    time_col = \"Time (s)\"\n",
    "    t = pd.to_numeric(df[time_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "    t = t[~np.isnan(t)]\n",
    "    dt = np.diff(t)\n",
    "    dt = dt[dt > 0]\n",
    "    if dt.size == 0:\n",
    "        raise ValueError(\"Cannot estimate fs: no positive time differences.\")\n",
    "    fs = 1.0 / np.median(dt)\n",
    "    return float(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b763947",
   "metadata": {},
   "source": [
    "**Filtering Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "827a1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values --> important so filters dont explode when they hit NaN\n",
    "def col_to_float_with_small_gap_fill(series: pd.Series) -> np.ndarray:\n",
    "    x = pd.to_numeric(series, errors=\"coerce\").astype(float)\n",
    "    x = x.interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "    return x.to_numpy()\n",
    "\n",
    "# high-pass filter to remove drift\n",
    "def highpass_filter(x: np.ndarray, fs: float, cutoff_hz: float = 20.0, order: int = 2) -> np.ndarray:\n",
    "    nyq = 0.5 * fs\n",
    "    sos = butter(order, cutoff_hz / nyq, btype=\"highpass\", output=\"sos\")\n",
    "    # sosfiltfilt applies the filter foward and backward, giving zero phase shift (envelope timing must match video labels)\n",
    "    return sosfiltfilt(sos, x)\n",
    "\n",
    "# notch filter 60Hz and 120Hz power line interference\n",
    "def notch_filter(x: np.ndarray, fs: float, freq_hz: float, q: float = 35.0) -> np.ndarray:\n",
    "    nyq = 0.5 * fs\n",
    "    if freq_hz >= nyq:\n",
    "        return x  # can't notch above Nyquist\n",
    "    w0 = freq_hz / nyq\n",
    "    b, a = iirnotch(w0, q)\n",
    "    return filtfilt(b, a, x)\n",
    "\n",
    "# band pass filter (keep EMG band)\n",
    "def bandpass_filter(x: np.ndarray, fs: float, low_hz: float = 20.0, high_hz: float = 450.0, order: int = 4) -> np.ndarray:\n",
    "    nyq = 0.5 * fs\n",
    "    high_hz = min(high_hz, 0.99 * nyq)\n",
    "    sos = butter(order, [low_hz / nyq, high_hz / nyq], btype=\"bandpass\", output=\"sos\")\n",
    "    return sosfiltfilt(sos, x)\n",
    "\n",
    "# rectify\n",
    "def rectify(x: np.ndarray) -> np.ndarray:\n",
    "    return np.abs(x)\n",
    "\n",
    "# low-pass filter\n",
    "def lowpass_filter(x: np.ndarray, fs: float, cutoff_hz: float = 5.0, order: int = 4) -> np.ndarray:\n",
    "    nyq = 0.5 * fs\n",
    "    sos = butter(order, cutoff_hz / nyq, btype=\"lowpass\", output=\"sos\")\n",
    "    return sosfiltfilt(sos, x)\n",
    "\n",
    "# get emg envelope (low-pass and rectified)\n",
    "def emg_envelope(x_bandpassed: np.ndarray, fs: float, envelope_lp_hz: float = 5.0) -> np.ndarray:\n",
    "    x_rect = rectify(x_bandpassed)\n",
    "    env = lowpass_filter(x_rect, fs=fs, cutoff_hz=envelope_lp_hz, order=4)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459dced9",
   "metadata": {},
   "source": [
    "**EMG Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8bbbdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emg_features(\n",
    "    df: pd.DataFrame,\n",
    "    emg_columns: list[str],\n",
    "    fs: float,\n",
    "    hp_hz: float = 20.0,\n",
    "    notch_freqs: tuple[float, ...] = (60.0, 120.0),\n",
    "    bp_low_hz: float = 20.0,\n",
    "    bp_high_hz: float = 450.0,\n",
    "    env_lp_hz: float = 5.0,\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    \n",
    "\n",
    "    # want to apply feature engineering to all emg columns\n",
    "    for col in emg_columns:\n",
    "        if col  in out.columns:      \n",
    "            # interpolate missing values\n",
    "            x = col_to_float_with_small_gap_fill(out[col])\n",
    "\n",
    "            # apply high pass filter\n",
    "            x = highpass_filter(x, fs=fs, cutoff_hz=hp_hz, order=2)\n",
    "\n",
    "            # apply notch filters\n",
    "            for f0 in notch_freqs:\n",
    "                x = notch_filter(x, fs=fs, freq_hz=f0, q=35.0)\n",
    "\n",
    "            # apply bandpass filter\n",
    "            x_bp = bandpass_filter(x, fs=fs, low_hz=bp_low_hz, high_hz=bp_high_hz, order=4)\n",
    "\n",
    "            # envelope emg\n",
    "            env = emg_envelope(x_bp, fs=fs, envelope_lp_hz=env_lp_hz)\n",
    "\n",
    "            out[col] = x_bp\n",
    "            out[f\"{col}_ENV\"] = env\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f44439",
   "metadata": {},
   "source": [
    "**Accelerometer Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a4af944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_accel_features(\n",
    "    df: pd.DataFrame,\n",
    "    sensor_ids: list[str],\n",
    "    fs: float,\n",
    "    accel_lowpass_hz: float = 20.0,\n",
    "    dyn_highpass_hz: float = 0.3,\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    for sid in sensor_ids:\n",
    "        ax = f\"{sid}_AccelX\"\n",
    "        ay = f\"{sid}_AccelY\"\n",
    "        az = f\"{sid}_AccelZ\"\n",
    "\n",
    "        # skip if missing\n",
    "        if not all(c in out.columns for c in [ax, ay, az]):\n",
    "            continue\n",
    "\n",
    "        # filter each axis (lowpass), then compute dynamic component (highpass)\n",
    "        for col in [ax, ay, az]:\n",
    "            x = col_to_float_with_small_gap_fill(out[col])\n",
    "\n",
    "            x_lp = lowpass_filter(x, fs=fs, cutoff_hz=accel_lowpass_hz, order=4)\n",
    "            x_dyn = highpass_filter(x_lp, fs=fs, cutoff_hz=dyn_highpass_hz, order=2)\n",
    "\n",
    "            out[col] = x_lp\n",
    "            out[f\"{col}_DYN\"] = x_dyn\n",
    "\n",
    "        # magnitudes (use low-passed signals)\n",
    "        out[f\"{sid}_AccelMag\"] = np.sqrt(out[ax]**2 + out[ay]**2 + out[az]**2)\n",
    "\n",
    "        # optional: magnitude of dynamic component\n",
    "        out[f\"{sid}_AccelMag_DYN\"] = np.sqrt(\n",
    "            out[f\"{ax}_DYN\"]**2 + out[f\"{ay}_DYN\"]**2 + out[f\"{az}_DYN\"]**2\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561c911",
   "metadata": {},
   "source": [
    "**Gyroscope Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5545330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gyro_features(\n",
    "    df: pd.DataFrame,\n",
    "    sensor_ids: list[str],\n",
    "    fs: float,\n",
    "    gyro_lowpass_hz: float = 20.0,\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    for sid in sensor_ids:\n",
    "        gx = f\"{sid}_GyroX\"\n",
    "        gy = f\"{sid}_GyroY\"\n",
    "        gz = f\"{sid}_GyroZ\"\n",
    "\n",
    "        # skip if missing\n",
    "        if not all(c in out.columns for c in [gx, gy, gz]):\n",
    "            continue\n",
    "\n",
    "        # low-pass each axis\n",
    "        for col in [gx, gy, gz]:\n",
    "            x = col_to_float_with_small_gap_fill(out[col])\n",
    "            x_lp = lowpass_filter(x, fs=fs, cutoff_hz=gyro_lowpass_hz, order=4)\n",
    "            out[col] = x_lp\n",
    "\n",
    "        # magnitude (use low-passed axes)\n",
    "        out[f\"{sid}_GyroMag\"] = np.sqrt(out[gx]**2 + out[gy]**2 + out[gz]**2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d3951",
   "metadata": {},
   "source": [
    "**Magnetometer Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bcb3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mag_features(\n",
    "    df: pd.DataFrame,\n",
    "    sensor_ids: list[str],\n",
    "    fs: float,\n",
    "    mag_lowpass_hz: float = 10.0,\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    for sid in sensor_ids:\n",
    "        mx = f\"{sid}_MagX\"\n",
    "        my = f\"{sid}_MagY\"\n",
    "        mz = f\"{sid}_MagZ\"\n",
    "\n",
    "        # skip if missing\n",
    "        if not all(c in out.columns for c in [mx, my, mz]):\n",
    "            continue\n",
    "\n",
    "        # low-pass each axis\n",
    "        for col in [mx, my, mz]:\n",
    "            x = col_to_float_with_small_gap_fill(out[col])\n",
    "            x_lp = lowpass_filter(x, fs=fs, cutoff_hz=mag_lowpass_hz, order=4)\n",
    "            out[col] = x_lp\n",
    "\n",
    "        # magnitude (use low-passed axes)\n",
    "        out[f\"{sid}_MagnetMag\"] = np.sqrt(out[mx]**2 + out[my]**2 + out[mz]**2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_ids = [\"A5F2\", \"A19E\"]\n",
    "\n",
    "\n",
    "emg_cols = []\n",
    "for id in sensor_ids:\n",
    "    emg_cols.append(f\"{id}_EMG1\")\n",
    "    emg_cols.append(f\"{id}_EMG2\")\n",
    "\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i]\n",
    "    df = clean_participant_df(df)\n",
    "    # get sampling rate\n",
    "    fs = estimate_fs_from_time(df)\n",
    "    df = add_emg_features(df, emg_cols, fs)\n",
    "    df = add_accel_features(df, sensor_ids, fs)\n",
    "    df = add_gyro_features(df, sensor_ids, fs)\n",
    "    df = add_mag_features(df, sensor_ids, fs)\n",
    "    dfs[i] = df\n",
    "\n",
    "full_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b09f56",
   "metadata": {},
   "source": [
    "**Separate Features and Labels and Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A5F2_AccelX', 'A5F2_AccelY', 'A5F2_AccelZ', 'A5F2_EMG1', 'A5F2_EMG2',\n",
      "       'A5F2_GyroX', 'A5F2_GyroY', 'A5F2_GyroZ', 'A5F2_MagX', 'A5F2_MagY',\n",
      "       'A5F2_MagZ', 'Event_Marker', 'A19E_AccelX', 'A19E_AccelY',\n",
      "       'A19E_AccelZ', 'A19E_EMG1', 'A19E_EMG2', 'A19E_GyroX', 'A19E_GyroY',\n",
      "       'A19E_GyroZ', 'A19E_MagX', 'A19E_MagY', 'A19E_MagZ', 'Time (s)',\n",
      "       'Primitive', 'A5F2_EMG1_ENV', 'A5F2_EMG2_ENV', 'A19E_EMG1_ENV',\n",
      "       'A19E_EMG2_ENV', 'A5F2_AccelX_DYN', 'A5F2_AccelY_DYN',\n",
      "       'A5F2_AccelZ_DYN', 'A19E_AccelX_DYN', 'A19E_AccelY_DYN',\n",
      "       'A19E_AccelZ_DYN', 'A5F2_AccelMag', 'A5F2_GyroMag', 'A5F2_MagnetMag',\n",
      "       'A19E_AccelMag', 'A19E_GyroMag', 'A19E_MagnetMag', 'A5F2_AccelX_Z',\n",
      "       'A5F2_AccelY_Z', 'A5F2_AccelZ_Z', 'A19E_AccelX_Z', 'A19E_AccelY_Z',\n",
      "       'A19E_AccelZ_Z', 'A5F2_GyroX_Z', 'A5F2_GyroY_Z', 'A5F2_GyroZ_Z',\n",
      "       'A19E_GyroX_Z', 'A19E_GyroY_Z', 'A19E_GyroZ_Z', 'A5F2_MagX_Z',\n",
      "       'A5F2_MagY_Z', 'A5F2_MagZ_Z', 'A19E_MagX_Z', 'A19E_MagY_Z',\n",
      "       'A19E_MagZ_Z', 'A5F2_AccelMag_Z', 'A5F2_GyroMag_Z', 'A5F2_MagnetMag_Z',\n",
      "       'A19E_AccelMag_Z', 'A19E_GyroMag_Z', 'A19E_MagnetMag_Z',\n",
      "       'participant_id', 'A5F2_AccelMag_DYN', 'A19E_AccelMag_DYN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# separate features, labels, and groups\n",
    "label_col = \"Primitive\"\n",
    "group_col = \"participant_id\"\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in full_df.columns\n",
    "    if c not in [label_col, group_col, \"Time (s)\", \"Event_Marker\"]\n",
    "]\n",
    "\n",
    "\n",
    "# independence is defined at the participant level\n",
    "# all samples from a participant must stay together in either train or test\n",
    "# this prevents: identity leakage, movement-style memorization, sensor placement bias\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
